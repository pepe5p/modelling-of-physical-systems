{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "author: Piotr Karaś"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGH Modelling of Physical Systems Lab 6 (2025 April 15th)\n",
    "Sylwester Arabas (sylwester.arabas@agh.edu.pl) & Emma Ware (ecware@ucdavis.edu) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Key concepts:**\n",
    "- [Coagulation](https://en.wikipedia.org/wiki/Coagulation_(disambiguation)) - growth of particles through aggregation\n",
    "- [Smoluchowski coagulation equation (SCE)](https://en.wikipedia.org/wiki/Smoluchowski_coagulation_equation) - deterministic mathematical model\n",
    "- [Golovin's analytic solution to SCE](http://mi.mathnet.ru/dan27630) for additive kernel and exponential initial condition\n",
    "- [Super-Droplet Method Monte-Carlo algorithm](https://arxiv.org/abs/physics/0701103) by Shima et al. 2007 ([patent in 2006](https://patents.google.com/patent/EP1847939A3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. particle-resolved random-sampled state representation for a mass-controled coagulation problem**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from time import monotonic\n",
    "\n",
    "\"\"\" targetting 100% nbqa-pylint clean code! :) \"\"\"\n",
    "\n",
    "from functools import partial\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot\n",
    "from open_atmos_jupyter_utils import show_plot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "PARAMS_PHYS = SimpleNamespace(\n",
    "    n0=2 ** 23,\n",
    "    dv_m3=1e6,\n",
    "    x0_kg=1.192e-13,\n",
    "    b_per_s=1500,\n",
    ")\n",
    "PARAMS_PHYS.dist = scipy.stats.expon(loc=0, scale=PARAMS_PHYS.x0_kg)\n",
    "PARAMS_PHYS.norm = PARAMS_PHYS.n0 * PARAMS_PHYS.dv_m3\n",
    "\n",
    "PARAMS_COMP = SimpleNamespace(\n",
    "    n_part=2 ** 11,\n",
    "    t_max_s=3600,\n",
    "    n_step=1800,\n",
    ")\n",
    "PARAMS_COMP.dt_s = PARAMS_COMP.t_max_s / PARAMS_COMP.n_step\n",
    "\n",
    "PARAMS_BINS = SimpleNamespace(\n",
    "    min_x=-12,\n",
    "    max_x=-5,\n",
    "    count=70\n",
    ")\n",
    "\n",
    "RNG = np.random.default_rng(seed=44)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def sample(*, params_comp, params_phys, rng):\n",
    "    \"\"\" randomly samples a particle population using constant-multiplicity,\n",
    "    uniform-mass and uniform-log-mass schemes and returns a dictionary\n",
    "    of three simulation state, each composed of 'mass' and 'mult' arrays \"\"\"\n",
    "    u01 = rng.uniform(0, 1, size=params_comp.n_part)\n",
    "    uniform_sampling_range = [params_phys.dist.ppf(q) for q in (.001, .999)]\n",
    "    x_uniform_linx = (\n",
    "        uniform_sampling_range[0]\n",
    "        + u01 * (uniform_sampling_range[1] - uniform_sampling_range[0])\n",
    "    )\n",
    "    x_uniform_logx = np.exp(\n",
    "        np.log(uniform_sampling_range[0])\n",
    "        + u01 * (np.log(uniform_sampling_range[1]) - np.log(uniform_sampling_range[0]))\n",
    "    )\n",
    "    return {\n",
    "        k: {\n",
    "            'mass': v['x'],\n",
    "            'mult': np.round(v['y'] * params_phys.norm).astype(int),\n",
    "        }\n",
    "        for k, v in\n",
    "        {\n",
    "            'sampling: uniform random in x': {\n",
    "                'x': x_uniform_linx,\n",
    "                'y': params_phys.dist.pdf(x_uniform_linx) \\\n",
    "                     * (uniform_sampling_range[1] - uniform_sampling_range[0]) \\\n",
    "                     / params_comp.n_part,\n",
    "            },\n",
    "            'sampling: uniform random in ln(x)': {\n",
    "                'x': x_uniform_logx,\n",
    "                'y': params_phys.dist.pdf(x_uniform_logx) \\\n",
    "                     * (np.log(uniform_sampling_range[1]) - np.log(uniform_sampling_range[0])) \\\n",
    "                     / (params_comp.n_part / x_uniform_logx),\n",
    "            },\n",
    "            'sampling: constant multiplicity': {\n",
    "                'x': params_phys.dist.ppf(u01),\n",
    "                'y': np.full(shape=params_comp.n_part, fill_value=1 / params_comp.n_part),\n",
    "            }\n",
    "        }.items()\n",
    "    }\n",
    "\n",
    "\n",
    "PARTICLES = sample(params_phys=PARAMS_PHYS, params_comp=PARAMS_COMP, rng=RNG)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def x_of_mass(mass):\n",
    "    \"\"\" defines the plot x coordinate as a funciton of particle mass \"\"\"\n",
    "    return np.log(mass) / 3\n",
    "\n",
    "\n",
    "def mass_of_x(coord):\n",
    "    \"\"\" computes mass back from the plot x coordinate \"\"\"\n",
    "    return np.exp(3 * coord)\n",
    "\n",
    "\n",
    "def kernel(mass_1, mass_2, coeff):\n",
    "    \"\"\" additive coagulation kernel \"\"\"\n",
    "    return coeff * (mass_1 + mass_2)\n",
    "\n",
    "\n",
    "def analytic_solution(mass_kg, time_s, params_phys):\n",
    "    \"\"\" Golovin's analytic solution to Smoluchowski coagulation equation \n",
    "    for additive kernel and exponential initial condition \"\"\"\n",
    "    tau = 1 - np.exp(-params_phys.n0 * params_phys.b_per_s * params_phys.x0_kg * time_s)\n",
    "    sqrt_tau = np.sqrt(tau)\n",
    "    return (\n",
    "        (1 - tau) / (mass_kg * sqrt_tau)\n",
    "        * scipy.special.ive(1, 2 * mass_kg / params_phys.x0_kg * sqrt_tau)  # pylint: disable=no-member\n",
    "        * np.exp(-(1 + tau - 2 * sqrt_tau) * mass_kg / params_phys.x0_kg)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot(*, particles, params_phys, params_comp, params_bins, rng, time=0):\n",
    "    \"\"\" plots the particle state as both a histogram as well as population scatter plot\n",
    "    (with random coordinates shuffled for the purpose of plotting) \"\"\"\n",
    "    _, axs = pyplot.subplot_mosaic(\n",
    "        [['hist'], ['part']],\n",
    "        figsize=(11, 6),\n",
    "        sharex=True,\n",
    "        tight_layout=True,\n",
    "    )\n",
    "    scale = params_phys.norm / params_comp.n_part\n",
    "    for k in particles:\n",
    "        axs['hist'].hist(\n",
    "            x=x_of_mass(particles[k]['mass']),\n",
    "            weights=particles[k]['mult'] / params_phys.norm * particles[k]['mass'],\n",
    "            bins=params_bins.count,\n",
    "            range=(params_bins.min_x, params_bins.max_x),\n",
    "            label=f'{k}',\n",
    "            alpha=.666,\n",
    "            density=True,\n",
    "        )\n",
    "        axs['part'].scatter(\n",
    "            x_of_mass(particles[k]['mass']),\n",
    "            rng.uniform(0, 1, params_comp.n_part),\n",
    "            s=.25 + 2 * particles[k]['mult'] / scale\n",
    "        )\n",
    "    lin_x, d_x = np.linspace(params_bins.min_x, params_bins.max_x, 256, retstep=True)\n",
    "    x_mean = lin_x[:-1] + d_x / 2\n",
    "    m_mean = mass_of_x(x_mean)\n",
    "    dn_dm = analytic_solution(mass_kg=m_mean, time_s=time, params_phys=params_phys)\n",
    "    axs['hist'].plot(\n",
    "        x_mean,\n",
    "        dn_dm * np.diff(mass_of_x(lin_x)) / np.diff(lin_x) * params_phys.norm * m_mean,\n",
    "        color='black',\n",
    "        label='Golovin solution'\n",
    "    )\n",
    "    axs['hist'].legend()\n",
    "    axs['hist'].set_ylabel(r'pdf(x) $\\cdot$ mass(x)')\n",
    "    axs['hist'].set_title(f'time: {time:.1f} s')\n",
    "    axs['hist'].set_xlim(params_bins.min_x, params_bins.max_x)\n",
    "    axs['part'].set_xlabel(r'$x = ln(\\sqrt[3]{m})$')\n",
    "    axs['part'].set_yticks([])\n",
    "    axs['part'].set_ylim(0, 1)\n",
    "    for axes in axs.values():\n",
    "        axes.grid()\n",
    "    show_plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot(\n",
    "    particles=PARTICLES,\n",
    "    params_phys=PARAMS_PHYS,\n",
    "    params_comp=PARAMS_COMP,\n",
    "    params_bins=PARAMS_BINS,\n",
    "    rng=RNG,\n",
    "    time=1e-5\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Monte-Carlo representation of coagulation dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def sdm(*, pairs, u01, mult, mass, kern, dt, dv):\n",
    "    \"\"\" performs Monte-Carlo coagulation using the SDM algorithm \"\"\"\n",
    "    for alpha, (j, k) in enumerate(pairs):\n",
    "        if mult[k] > mult[j]:\n",
    "            j, k = k, j\n",
    "\n",
    "        rate = kern(mass[j], mass[k])\n",
    "        p = rate * dt * mult[j] / dv / len(pairs)\n",
    "        n = len(mult)\n",
    "        p_ratio = (n * (n - 1)) / 2\n",
    "        p *= p_ratio\n",
    "\n",
    "        if p < u01[alpha]:\n",
    "            continue\n",
    "\n",
    "        if mult[k] != mult[j]:\n",
    "            mult[j] -= mult[k]\n",
    "            mass[k] += mass[j]\n",
    "        else:\n",
    "            mass[k] += mass[j]\n",
    "            mass[j] = mass[k]\n",
    "            mult[j] = mult[k] // 2\n",
    "            mult[k] -= mult[j]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def simulate(*, params_phys, params_comp, particles, rng):\n",
    "    \"\"\" does simulation for all sampling variants (each variant using the same shuffled numbers) \"\"\"\n",
    "    n_pairs = params_comp.n_part // 2\n",
    "    kern = partial(kernel, coeff=params_phys.b_per_s)\n",
    "    for _ in range(params_comp.n_step):\n",
    "        non_overlapping_pairs = rng.permutation(params_comp.n_part)[: 2 * n_pairs].reshape(-1, 2)\n",
    "        u01 = rng.uniform(0, 1, n_pairs)\n",
    "        for part in particles.values():\n",
    "            sdm(\n",
    "                pairs=non_overlapping_pairs,\n",
    "                u01=u01,\n",
    "                kern=kern,\n",
    "                dt=params_comp.dt_s,\n",
    "                dv=params_phys.dv_m3,\n",
    "                **part\n",
    "            )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "simulate(particles=PARTICLES, params_phys=PARAMS_PHYS, params_comp=PARAMS_COMP, rng=RNG)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot(\n",
    "    particles=PARTICLES,\n",
    "    params_phys=PARAMS_PHYS,\n",
    "    params_comp=PARAMS_COMP,\n",
    "    params_bins=PARAMS_BINS,\n",
    "    rng=RNG,\n",
    "    time=PARAMS_COMP.t_max_s,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from numba import njit\n",
    "\n",
    "\n",
    "@njit(inline=\"always\")\n",
    "def kernel_parallel(mass_1, mass_2, coeff):\n",
    "    \"\"\" additive coagulation kernel \"\"\"\n",
    "    return coeff * (mass_1 + mass_2)\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def sdm_parallel(*, pairs, u01, mult, mass, kern, dt, dv, coeff):\n",
    "    \"\"\" performs Monte-Carlo coagulation using the SDM algorithm \"\"\"\n",
    "    for alpha, (j, k) in enumerate(pairs):\n",
    "        if mult[k] > mult[j]:\n",
    "            j, k = k, j\n",
    "\n",
    "        rate = kern(mass[j], mass[k], coeff)\n",
    "        p = rate * dt * mult[j] / dv / len(pairs)\n",
    "        n = len(mult)\n",
    "        p_ratio = (n * (n - 1)) / 2\n",
    "        p *= p_ratio\n",
    "\n",
    "        if p < u01[alpha]:\n",
    "            continue\n",
    "\n",
    "        if mult[k] != mult[j]:\n",
    "            mult[j] -= mult[k]\n",
    "            mass[k] += mass[j]\n",
    "        else:\n",
    "            mass[k] += mass[j]\n",
    "            mass[j] = mass[k]\n",
    "            mult[j] = mult[k] // 2\n",
    "            mult[k] -= mult[j]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "def _process_chunk(chunk, pairs, u01, kern, dt, dv, coeff):\n",
    "    \"\"\"Apply sdm to each particle state in this chunk.\"\"\"\n",
    "    for part in chunk:\n",
    "        sdm_parallel(\n",
    "            pairs=pairs,\n",
    "            u01=u01,\n",
    "            kern=kern,\n",
    "            dt=dt,\n",
    "            dv=dv,\n",
    "            coeff=coeff,\n",
    "            **part\n",
    "        )\n",
    "\n",
    "def simulate_parallel(\n",
    "    *, params_phys, params_comp, particles, rng, n_workers=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Parallel version of simulate:\n",
    "      - splits the particles into n_workers chunks\n",
    "      - for each time‐step, computes the same pairs & uniforms\n",
    "      - submits each chunk to the thread pool for sdm()\n",
    "    \"\"\"\n",
    "    # Pre-split the particle states into n_workers lists\n",
    "    parts = list(particles.values())\n",
    "    chunks = np.array_split(parts, n_workers)\n",
    "\n",
    "    # Make a fixed executor\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        for _ in range(params_comp.n_step):\n",
    "            # draw all the random numbers for this step once\n",
    "            flat = rng.permutation(params_comp.n_part)[: 2 * (params_comp.n_part // 2)]\n",
    "            pairs = flat.reshape(-1, 2)\n",
    "            u01 = rng.uniform(0.0, 1.0, len(pairs))\n",
    "\n",
    "            # dispatch each chunk\n",
    "            futures = [\n",
    "                executor.submit(\n",
    "                    _process_chunk,\n",
    "                    chunk,\n",
    "                    pairs,\n",
    "                    u01,\n",
    "                    kernel_parallel,\n",
    "                    params_comp.dt_s,\n",
    "                    params_phys.dv_m3,\n",
    "                    params_phys.b_per_s,\n",
    "                )\n",
    "                for chunk in chunks\n",
    "            ]\n",
    "\n",
    "            # wait for them all to finish\n",
    "            for f in futures:\n",
    "                f.result()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "from time import monotonic\n",
    "\n",
    "PARTICLES_1 = sample(params_phys=PARAMS_PHYS, params_comp=PARAMS_COMP, rng=RNG)\n",
    "PARTICLES_2 = deepcopy(PARTICLES_1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RNG = np.random.default_rng(seed=2137)\n",
    "start = monotonic()\n",
    "simulate(particles=PARTICLES_1, params_phys=PARAMS_PHYS, params_comp=PARAMS_COMP, rng=RNG)\n",
    "end = monotonic()\n",
    "one_thread_time = end - start"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RNG = np.random.default_rng(seed=2137)\n",
    "start = monotonic()\n",
    "simulate_parallel(particles=PARTICLES_2, params_phys=PARAMS_PHYS, params_comp=PARAMS_COMP, rng=RNG)\n",
    "end = monotonic()\n",
    "parallel_time = end - start"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"One thread took {one_thread_time:.2f} seconds\")\n",
    "print(f\"Parallel took {parallel_time:.2f} seconds\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    particles=PARTICLES_1,\n",
    "    params_phys=PARAMS_PHYS,\n",
    "    params_comp=PARAMS_COMP,\n",
    "    params_bins=PARAMS_BINS,\n",
    "    rng=RNG,\n",
    "    time=PARAMS_COMP.t_max_s,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot(\n",
    "    particles=PARTICLES_2,\n",
    "    params_phys=PARAMS_PHYS,\n",
    "    params_comp=PARAMS_COMP,\n",
    "    params_bins=PARAMS_BINS,\n",
    "    rng=RNG,\n",
    "    time=PARAMS_COMP.t_max_s,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def bitwise_compare(particles_1, particles_2) -> bool:\n",
    "    \"\"\" compares two particle populations bitwise \"\"\"\n",
    "    bs1 = pickle.dumps(particles_1, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    bs2 = pickle.dumps(particles_2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return bs1 == bs2\n",
    "\n",
    "\n",
    "particles_eq = bitwise_compare(\n",
    "    particles_1=PARTICLES_1,\n",
    "    particles_2=PARTICLES_2,\n",
    ")\n",
    "print(f\"Particles are equal: {particles_eq}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
